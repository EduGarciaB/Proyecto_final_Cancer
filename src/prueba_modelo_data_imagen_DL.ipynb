{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a diseñar un enfoque para entrenar un modelo único usando tanto el dataset tabular como las imágenes. Dado que tu dataset es desbalanceado y contiene valores faltantes, es crucial preparar adecuadamente los datos antes de entrenar el modelo. Aquí te explico cómo puedes proceder.\n",
    "\n",
    "1. Preprocesamiento de Datos\n",
    "\n",
    "1.1. Preprocesamiento del Dataset Tabular\n",
    "\n",
    "\t1.\tManejo de Valores Faltantes:\n",
    "\t•\tCategorías Missing: Para columnas categóricas con valores faltantes (como sex, age_approx, anatom_site_general), puedes reemplazar los valores faltantes con una categoría especial como “missing”. Esto se hace para mantener la información de que estos datos estaban ausentes.\n",
    "\t•\tCodificación: Utiliza OneHotEncoder o pd.get_dummies para convertir las variables categóricas en variables dummy. Asegúrate de incluir la categoría “missing” como una opción.\n",
    "\t2.\tEscalado de Datos:\n",
    "\t•\tLas variables numéricas pueden necesitar escalado. Utiliza StandardScaler o MinMaxScaler para normalizar los datos.\n",
    "\t3.\tBalanceo del Dataset:\n",
    "\t•\tDado el desbalance en tu objetivo (target), puedes considerar técnicas de balanceo como SMOTE o undersampling para equilibrar las clases.\n",
    "\t4.\tDivisión del Dataset:\n",
    "\t•\tDivide el dataset en conjuntos de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lirerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16_ISIC_0000001.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16_ISIC_0000002.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16_ISIC_0000004.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16_ISIC_0000006.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16_ISIC_0000007.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71365</th>\n",
       "      <td>20_ISIC_9999134.jpg</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71366</th>\n",
       "      <td>20_ISIC_9999320.jpg</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71367</th>\n",
       "      <td>20_ISIC_9999515.jpg</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71368</th>\n",
       "      <td>20_ISIC_9999666.jpg</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71369</th>\n",
       "      <td>20_ISIC_9999806.jpg</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71370 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_id   sex  age_approx anatom_site_general  target\n",
       "0      16_ISIC_0000001.jpg   NaN         NaN                 NaN       0\n",
       "1      16_ISIC_0000002.jpg   NaN         NaN                 NaN       1\n",
       "2      16_ISIC_0000004.jpg   NaN         NaN                 NaN       1\n",
       "3      16_ISIC_0000006.jpg   NaN         NaN                 NaN       0\n",
       "4      16_ISIC_0000007.jpg   NaN         NaN                 NaN       0\n",
       "...                    ...   ...         ...                 ...     ...\n",
       "71365  20_ISIC_9999134.jpg  male        50.0               torso       0\n",
       "71366  20_ISIC_9999320.jpg  male        65.0               torso       0\n",
       "71367  20_ISIC_9999515.jpg  male        20.0     lower extremity       0\n",
       "71368  20_ISIC_9999666.jpg  male        50.0     lower extremity       0\n",
       "71369  20_ISIC_9999806.jpg  male        45.0               torso       0\n",
       "\n",
       "[71370 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el DataFrame \n",
    "df = pd.read_csv('/Users/luiseduardogarciablanco/Desktop/nueva data cancer/prueba_data_16_20/dataset_16_20.csv')\n",
    "\n",
    "# Asegurarse de que la columna 'image_id' tenga la extensión '.jpg'\n",
    "df['image_id'] = df['image_id'].apply(lambda x: x if x.endswith('.jpg') else x + '.jpg')\n",
    "\n",
    "# Convertir la columna target a entero\n",
    "df['target'] = df['target'].astype(int)\n",
    "\n",
    "# Dividir el DataFrame en conjunto de entrenamiento y validación\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, stratify=df['target'], random_state=42)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X_train = df_train[['image_id', 'sex', 'age_approx', 'anatom_site_general']]\n",
    "y_train = df_train['target']\n",
    "\n",
    "X_val = df_val[['image_id', 'sex', 'age_approx', 'anatom_site_general']]\n",
    "y_val = df_val['target']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 19:52:41.779488: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-08-25 19:52:41.779528: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-08-25 19:52:41.779537: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-08-25 19:52:41.779832: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-25 19:52:41.779875: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.resize(image, [100, 100])\n",
    "    image = image / 255.0  # Normalizar\n",
    "    return image\n",
    "\n",
    "# Crear un Dataset para las imágenes\n",
    "def image_generator(df, directory, batch_size):\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch_df = df.iloc[i:i+batch_size]\n",
    "        images = []\n",
    "        labels = []\n",
    "        for _, row in batch_df.iterrows():\n",
    "            image_path = f'{directory}/{row[\"image_id\"]}'\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.image.decode_jpeg(image, channels=3)\n",
    "            image = preprocess_image(image)\n",
    "            images.append(image)\n",
    "            labels.append(row[\"target\"])\n",
    "        yield np.array(images), np.array(labels)\n",
    "\n",
    "# Crear datasets para entrenamiento y validación\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: image_generator(df_train, '/Users/luiseduardogarciablanco/Desktop/nueva data cancer/prueba_data_16_20/image', 32),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    ").shuffle(1000).batch(32)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: image_generator(df_val, '/Users/luiseduardogarciablanco/Desktop/nueva data cancer/prueba_data_16_20/image', 32),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    ").batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tabular(df):\n",
    "    # Convertir datos tabulares a numpy arrays\n",
    "    X = df[['sex', 'age_approx', 'anatom_site_general']].values\n",
    "    return X\n",
    "\n",
    "# Procesar datos tabulares para entrenamiento y validación\n",
    "X_train_tabular = preprocess_tabular(df_train)\n",
    "X_val_tabular = preprocess_tabular(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57096 validated image filenames belonging to 2 classes.\n",
      "Found 14274 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_train['target'] = df_train['target'].astype(str)\n",
    "df_val['target'] = df_val['target'].astype(str)\n",
    "\n",
    "# Crear generador de imágenes\n",
    "def image_generator(df, image_directory, batch_size):\n",
    "    image_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "    return image_datagen.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory=image_directory,\n",
    "        x_col='image_id',\n",
    "        y_col='target',\n",
    "        target_size=(100, 100),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "# Preprocesar datos tabulares\n",
    "def preprocess_tabular(df):\n",
    "    # Aquí puedes aplicar cualquier preprocesamiento necesario\n",
    "    # Ejemplo: convertir a numpy array y normalizar\n",
    "    return df.to_numpy()\n",
    "\n",
    "# Crear un generador combinado para imágenes y datos tabulares\n",
    "def combined_generator(image_gen, df_tabular):\n",
    "    def generator():\n",
    "        for images, labels in image_gen:\n",
    "            # Obtener índices del batch de imágenes\n",
    "            indices = np.arange(len(images))\n",
    "            tabular_data = preprocess_tabular(df_tabular.iloc[indices])\n",
    "            yield [images, tabular_data], labels\n",
    "    return generator\n",
    "\n",
    "# Crear generadores para entrenamiento y validación\n",
    "train_image_gen = image_generator(df_train, '/Users/luiseduardogarciablanco/Desktop/nueva data cancer/prueba_data_16_20/image', 32)\n",
    "val_image_gen = image_generator(df_val, '/Users/luiseduardogarciablanco/Desktop/nueva data cancer/prueba_data_16_20/image', 32)\n",
    "\n",
    "train_gen = combined_generator(train_image_gen, df_train)\n",
    "val_gen = combined_generator(val_image_gen, df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Concatenate\n",
    "\n",
    "# Definir las entradas\n",
    "image_input = Input(shape=(100, 100, 3))\n",
    "tabular_input = Input(shape=(100))\n",
    "\n",
    "# Definir el modelo de imagen\n",
    "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Concatenar con los datos tabulares\n",
    "x = Concatenate()([x, tabular_input])\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Model(inputs=[image_input, tabular_input], outputs=output)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Definir el callback EarlyStopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',  # Métrica a monitorear\n",
    "    patience=5,          # Número de épocas sin mejora para detener el entrenamiento\n",
    "    restore_best_weights=True  # Restaurar los mejores pesos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    x=train_gen(),\n",
    "    validation_data=val_gen(),\n",
    "    epochs=15,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
