{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Suprimir todos los warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Listar los dispositivos físicos disponibles, en este caso, GPUs\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Si hay alguna GPU disponible\n",
    "if len(physical_devices) > 0:\n",
    "    # Permitir que TensorFlow crezca dinámicamente la memoria utilizada en la GPU\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "physical_devices\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              image_id      sex  age_approx anatom_site_general  target\n",
      "0  16_ISIC_0000001.jpg  Unknown          -1             Unknown       0\n",
      "1  16_ISIC_0000002.jpg  Unknown          -1             Unknown       1\n",
      "2  16_ISIC_0000004.jpg  Unknown          -1             Unknown       1\n",
      "3  16_ISIC_0000006.jpg  Unknown          -1             Unknown       0\n",
      "4  16_ISIC_0000007.jpg  Unknown          -1             Unknown       0\n",
      "target\n",
      "0    64604\n",
      "1     6766\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar el dataset\n",
    "\n",
    "#metadata_path = '/Users/luiseduardogarciablanco/Desktop/nueva data cancer/prueba_data_16_20/dataset_16_20_emb.csv'\n",
    "metadata = pd.read_csv('/Users/luiseduardogarciablanco/Desktop/nueva data cancer/prueba_data_16_20/dataset_16_20_emb.csv')  # Usar la primera columna como índice\n",
    "\n",
    "\n",
    "# Ruta a las imágenes\n",
    "image_path = \"/Users/luiseduardogarciablanco/Desktop/nueva data cancer/prueba_data_16_20/image\"\n",
    "\n",
    "\n",
    "# Mostrar información básica del dataset\n",
    "print (metadata.head())\n",
    "print(metadata['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16_ISIC_0000001.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16_ISIC_0000002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16_ISIC_0000004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16_ISIC_0000006.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16_ISIC_0000007.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71365</th>\n",
       "      <td>20_ISIC_9999134.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71366</th>\n",
       "      <td>20_ISIC_9999320.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71367</th>\n",
       "      <td>20_ISIC_9999515.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71368</th>\n",
       "      <td>20_ISIC_9999666.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71369</th>\n",
       "      <td>20_ISIC_9999806.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_id  target\n",
       "0      16_ISIC_0000001.jpg       0\n",
       "1      16_ISIC_0000002.jpg       1\n",
       "2      16_ISIC_0000004.jpg       1\n",
       "3      16_ISIC_0000006.jpg       0\n",
       "4      16_ISIC_0000007.jpg       0\n",
       "...                    ...     ...\n",
       "71365  20_ISIC_9999134.jpg       0\n",
       "71366  20_ISIC_9999320.jpg       0\n",
       "71367  20_ISIC_9999515.jpg       0\n",
       "71368  20_ISIC_9999666.jpg       0\n",
       "71369  20_ISIC_9999806.jpg       0\n",
       "\n",
       "[71370 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = metadata [['image_id', 'target']]\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    6766\n",
      "1    6766\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13532 entries, 0 to 13531\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   image_id  13532 non-null  object\n",
      " 1   target    13532 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 211.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "df = metadata\n",
    "\n",
    "# Dividir el DataFrame en dos partes según el valor del target\n",
    "df_majority = df[df['target'] == 0]\n",
    "df_minority = df[df['target'] == 1]\n",
    "\n",
    "# Reducir el número de muestras de la clase mayoritaria a 6766 para quilibrar las muestras\n",
    "df_majority_downsampled = df_majority.sample(n=6766, random_state=42)\n",
    "\n",
    "# Combinar los DataFrames balanceados\n",
    "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Opcional: Mezclar el DataFrame balanceado para asegurar aleatoriedad\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Mostrar la distribución de clases después del balanceo\n",
    "print(df_balanced['target'].value_counts())\n",
    "\n",
    "df_balanced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20_ISIC_8376677.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18_ISIC_0024932.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20_ISIC_3449574.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20_ISIC_8143299.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20_ISIC_0189336.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13527</th>\n",
       "      <td>18_ISIC_0033910.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13528</th>\n",
       "      <td>20_ISIC_8040024.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13529</th>\n",
       "      <td>20_ISIC_5667935.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13530</th>\n",
       "      <td>20_ISIC_5310630.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13531</th>\n",
       "      <td>17_ISIC_0014366.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_id  target\n",
       "0      20_ISIC_8376677.jpg       0\n",
       "1      18_ISIC_0024932.jpg       1\n",
       "2      20_ISIC_3449574.jpg       0\n",
       "3      20_ISIC_8143299.jpg       0\n",
       "4      20_ISIC_0189336.jpg       0\n",
       "...                    ...     ...\n",
       "13527  18_ISIC_0033910.jpg       0\n",
       "13528  20_ISIC_8040024.jpg       1\n",
       "13529  20_ISIC_5667935.jpg       0\n",
       "13530  20_ISIC_5310630.jpg       0\n",
       "13531  17_ISIC_0014366.jpg       1\n",
       "\n",
       "[13532 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata= df_balanced\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'target' a string\n",
    "metadata['target'] = metadata['target'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10825, 2)\n",
      "(2707, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dividir los datos en entrenamiento y validación\n",
    "train_df, val_df = train_test_split(metadata, test_size=0.2, stratify=metadata['target'], random_state=42)\n",
    "\n",
    "print (train_df.shape)\n",
    "print (val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los valores de la columna target a cadenas de texto\n",
    "train_df['target'] = train_df['target'].astype(str)\n",
    "val_df['target'] = val_df['target'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10826 validated image filenames belonging to 2 classes.\n",
      "Found 2706 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Directorio de las imágenes\n",
    "image_path = '/Users/luiseduardogarciablanco/Desktop/nueva data cancer/prueba_data_16_20/image'\n",
    "'''\n",
    "# Función para ajustar la nitidez\n",
    "def adjust_sharpness(image):\n",
    "    # Asegúrate de que la imagen esté en el rango uint8 antes de convertir\n",
    "    if image.dtype != np.uint8:\n",
    "        image = (image * 255).astype(np.uint8)  # Ajuste para imagen normalizada\n",
    "    image = Image.fromarray(image)\n",
    "    enhancer = ImageEnhance.Sharpness(image)\n",
    "    image = enhancer.enhance(2.0)  # Aumenta la nitidez\n",
    "    return np.array(image) / 255.0  # Convierte de vuelta a rango [0, 1]\n",
    "\n",
    "# Función para ajustar el contraste\n",
    "def adjust_contrast(image):\n",
    "    # Asegúrate de que la imagen esté en el rango uint8 antes de convertir\n",
    "    if image.dtype != np.uint8:\n",
    "        image = (image * 255).astype(np.uint8)  # Ajuste para imagen normalizada\n",
    "    image = Image.fromarray(image)\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(1.5)  # Aumenta el contraste\n",
    "    return np.array(image) / 255.0  # Convierte de vuelta a rango [0, 1]\n",
    "\n",
    "# Función de preprocesamiento que combina ambas\n",
    "def preprocess_function(image):\n",
    "    image = adjust_sharpness(image)\n",
    "    image = adjust_contrast(image)\n",
    "    return image\n",
    "\n",
    "# Crear generadores de datos con augmentación\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,  # División para validación\n",
    "    preprocessing_function=preprocess_function  # Añade la función personalizada\n",
    ")\n",
    "\n",
    "'''\n",
    "# Crear generadores de datos con augmentación\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #rescale=1./255,\n",
    "    #rotation_range=20,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #horizontal_flip=True,'''\n",
    "    validation_split=0.2  # División para validación\n",
    ")\n",
    "#generador de entrenamiento\n",
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "    dataframe=metadata,\n",
    "    directory=image_path,\n",
    "    x_col='image_id',\n",
    "    y_col='target',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "#generador de validacion\n",
    "val_gen = train_datagen.flow_from_dataframe(\n",
    "    dataframe=metadata,\n",
    "    directory=image_path,\n",
    "    x_col='image_id',\n",
    "    y_col='target',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 16:45:51.481405: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.8119 - accuracy: 0.7283 - precision_2: 0.7296 - recall_2: 0.7289 - auc: 0.8015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 16:46:52.353526: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 77s 222ms/step - loss: 0.8119 - accuracy: 0.7283 - precision_2: 0.7296 - recall_2: 0.7289 - auc: 0.8015 - val_loss: 0.5599 - val_accuracy: 0.7772 - val_precision_2: 0.7261 - val_recall_2: 0.8792 - val_auc: 0.8662\n",
      "Epoch 2/5\n",
      "339/339 [==============================] - 73s 215ms/step - loss: 0.6080 - accuracy: 0.7753 - precision_2: 0.7756 - recall_2: 0.7769 - auc: 0.8552 - val_loss: 0.4710 - val_accuracy: 0.7997 - val_precision_2: 0.7772 - val_recall_2: 0.8320 - val_auc: 0.8835\n",
      "Epoch 3/5\n",
      "339/339 [==============================] - 73s 215ms/step - loss: 0.5183 - accuracy: 0.8021 - precision_2: 0.8008 - recall_2: 0.8064 - auc: 0.8824 - val_loss: 0.4874 - val_accuracy: 0.8067 - val_precision_2: 0.7914 - val_recall_2: 0.8252 - val_auc: 0.8863\n",
      "Epoch 4/5\n",
      "339/339 [==============================] - 73s 215ms/step - loss: 0.4608 - accuracy: 0.8195 - precision_2: 0.8166 - recall_2: 0.8259 - auc: 0.9010 - val_loss: 0.4971 - val_accuracy: 0.8156 - val_precision_2: 0.7844 - val_recall_2: 0.8627 - val_auc: 0.8890\n",
      "Epoch 5/5\n",
      "339/339 [==============================] - 72s 214ms/step - loss: 0.4021 - accuracy: 0.8396 - precision_2: 0.8373 - recall_2: 0.8447 - auc: 0.9199 - val_loss: 0.4456 - val_accuracy: 0.8252 - val_precision_2: 0.8007 - val_recall_2: 0.8590 - val_auc: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 16:52:00.012223: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.8002 - precision_3: 0.8010 - recall_3: 0.8008 - auc: 0.8801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 16:53:25.300214: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 103s 294ms/step - loss: 0.6443 - accuracy: 0.8002 - precision_3: 0.8010 - recall_3: 0.8008 - auc: 0.8801 - val_loss: 0.6820 - val_accuracy: 0.7967 - val_precision_3: 0.7371 - val_recall_3: 0.9130 - val_auc: 0.8877\n",
      "Epoch 2/10\n",
      "339/339 [==============================] - 97s 285ms/step - loss: 0.4125 - accuracy: 0.8618 - precision_3: 0.8623 - recall_3: 0.8623 - auc: 0.9335 - val_loss: 0.6059 - val_accuracy: 0.8234 - val_precision_3: 0.7833 - val_recall_3: 0.8867 - val_auc: 0.9012\n",
      "Epoch 3/10\n",
      "339/339 [==============================] - 96s 284ms/step - loss: 0.2779 - accuracy: 0.8996 - precision_3: 0.8992 - recall_3: 0.9010 - auc: 0.9631 - val_loss: 0.7120 - val_accuracy: 0.8204 - val_precision_3: 0.7603 - val_recall_3: 0.9280 - val_auc: 0.9061\n",
      "Epoch 4/10\n",
      "339/339 [==============================] - 97s 285ms/step - loss: 0.1904 - accuracy: 0.9315 - precision_3: 0.9316 - recall_3: 0.9319 - auc: 0.9803 - val_loss: 0.5796 - val_accuracy: 0.8437 - val_precision_3: 0.8227 - val_recall_3: 0.8702 - val_auc: 0.9108\n",
      "Epoch 5/10\n",
      "339/339 [==============================] - 97s 287ms/step - loss: 0.1335 - accuracy: 0.9530 - precision_3: 0.9541 - recall_3: 0.9521 - auc: 0.9886 - val_loss: 0.6874 - val_accuracy: 0.8333 - val_precision_3: 0.7901 - val_recall_3: 0.9010 - val_auc: 0.9102\n",
      "Epoch 6/10\n",
      "339/339 [==============================] - 97s 286ms/step - loss: 0.0860 - accuracy: 0.9689 - precision_3: 0.9689 - recall_3: 0.9691 - auc: 0.9948 - val_loss: 0.6868 - val_accuracy: 0.8385 - val_precision_3: 0.8039 - val_recall_3: 0.8890 - val_auc: 0.9101\n",
      "Epoch 7/10\n",
      "339/339 [==============================] - 97s 287ms/step - loss: 0.0544 - accuracy: 0.9800 - precision_3: 0.9794 - recall_3: 0.9809 - auc: 0.9978 - val_loss: 0.6806 - val_accuracy: 0.8500 - val_precision_3: 0.8313 - val_recall_3: 0.8725 - val_auc: 0.9134\n",
      "85/85 [==============================] - 15s 170ms/step - loss: 0.5796 - accuracy: 0.8437 - precision_3: 0.8227 - recall_3: 0.8702 - auc: 0.9108\n",
      "Test Loss: 0.5796287655830383\n",
      "Test Accuracy: 0.8436806797981262\n",
      "Test Precision: 0.8226950168609619\n",
      "Test Recall: 0.8702175617218018\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l1_l2\n",
    "# Cargar el modelo preentrenado ResNet50 (sin la parte superior)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Congelar las capas del modelo base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Añadir capas adicionales\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid',kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))\n",
    "    #layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), tf.keras.metrics.AUC(name='auc')])\n",
    "#model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Entrenamiento inicial (solo las capas superiores)\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=5,\n",
    "    validation_data=val_gen\n",
    ")\n",
    "\n",
    "# Descongelar algunas capas del modelo base para fine-tuning\n",
    "#for layer in base_model.layers[-10:]:# probaremos a dscongelar 20, 40 y 60 capas para comprobar la eficacia del modelo\n",
    "for layer in base_model.layers[-40:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compilar de nuevo con una tasa de aprendizaje más baja\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Calcular los pesos de clase\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(metadata['target']), y=metadata['target'])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entrenamiento con Fine-Tuning\n",
    "history_fine = model.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    validation_data=val_gen,\n",
    "    #class_weight=class_weights, # debe desactivarse si los datos están balanceados\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Evaluar el modelo para obtener el AUC-ROC\n",
    "evaluation = model.evaluate(val_gen)\n",
    "print(f\"Test Loss: {evaluation[0]}\")\n",
    "print(f\"Test Accuracy: {evaluation[1]}\")\n",
    "print(f\"Test Precision: {evaluation[2]}\")\n",
    "print(f\"Test Recall: {evaluation[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 14s 166ms/step - loss: 0.5796 - accuracy: 0.8437 - precision_3: 0.8227 - recall_3: 0.8702 - auc: 0.9108\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "loss, accuracy, precision, recall, auc= model.evaluate(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 13s 160ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.87      0.82      0.84      1373\n",
      "     Class 1       0.82      0.87      0.85      1333\n",
      "\n",
      "    accuracy                           0.84      2706\n",
      "   macro avg       0.84      0.84      0.84      2706\n",
      "weighted avg       0.84      0.84      0.84      2706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las probabilidades\n",
    "y_pred_probs = model.predict(val_gen)\n",
    "\n",
    "# Ajustar el umbral de decisión\n",
    "threshold = 0.5 # Ajustar según sea necesario\n",
    "y_pred_adjusted = (y_pred_probs > threshold).astype(int)\n",
    "\n",
    "# Calcular y mostrar métricas\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = val_gen.classes\n",
    "print(classification_report(y_true, y_pred_adjusted, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descongelando 10 capas conseguimos el siguiente resultado:\n",
    "\n",
    "85/85 [==============================] - 19s 214ms/step\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0       0.84      0.79      0.82      1373\n",
    "     Class 1       0.80      0.85      0.82      1333\n",
    "\n",
    "    accuracy                           0.82      2706\n",
    "   macro avg       0.82      0.82      0.82      2706\n",
    "weighted avg       0.82      0.82      0.82      2706\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descongelando 20 capas conseguimos el sigiuente resultado:\n",
    "\n",
    "85/85 [==============================] - 16s 177ms/step\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0       0.84      0.82      0.83      1373\n",
    "     Class 1       0.82      0.84      0.83      1333\n",
    "\n",
    "    accuracy                           0.83      2706\n",
    "   macro avg       0.83      0.83      0.83      2706\n",
    "weighted avg       0.83      0.83      0.83      2706\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descongelando 40 dio este resultado:\n",
    "85/85 [==============================] - 16s 179ms/step\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0       0.87      0.82      0.85      1373\n",
    "     Class 1       0.82      0.88      0.85      1333\n",
    "\n",
    "    accuracy                           0.85      2706\n",
    "   macro avg       0.85      0.85      0.85      2706\n",
    "weighted avg       0.85      0.85      0.85      2706\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descongelando 60 dio este resultado:\n",
    "85/85 [==============================] - 15s 167ms/step\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0       0.85      0.83      0.84      1373\n",
    "     Class 1       0.83      0.85      0.84      1333\n",
    "\n",
    "    accuracy                           0.84      2706\n",
    "   macro avg       0.84      0.84      0.84      2706\n",
    "weighted avg       0.84      0.84      0.84      2706\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('resnet50_fine_tuned_model_40.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
