{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib  # Para cargar predicciones crudas\n",
    "\n",
    "# Suprimir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sc/w6cv9_291mqc4c1m0qn06_4m0000gn/T/ipykernel_70449/3094498416.py:11: DtypeWarning: Columns (49,50,51,52,53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/luiseduardogarciablanco/Desktop/nueva data cancer/2024/df_train_processed.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib  # Importar joblib directamente\n",
    "import xgboost as xgb\n",
    "\n",
    "# 1. Cargar el modelo entrenado\n",
    "model_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/metadata_model.pkl'  # Reemplaza con la ruta de tu modelo\n",
    "modelo = joblib.load(model_path)  # Cargar el modelo entrenado\n",
    "\n",
    "# 2. Cargar el dataset de entrada (con los metadatos que usarás para predecir)\n",
    "\n",
    "df = pd.read_csv('/Users/luiseduardogarciablanco/Desktop/nueva data cancer/2024/df_train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma de los valores en cada columna después de eliminar las especificadas:\n",
      "isic_id                   ISIC_0015670ISIC_0015845ISIC_0015864ISIC_00159...\n",
      "target                                                                  389\n",
      "age_approx                                                       22744720.0\n",
      "clin_size_long_diam_mm                                           1543138.72\n",
      "tbp_lv_A                                                     7834635.994465\n",
      "                                                ...                        \n",
      "onehot_38                                                              7976\n",
      "onehot_39                                                             48223\n",
      "onehot_40                                                            127915\n",
      "onehot_41                                                             63003\n",
      "onehot_42                                                             12638\n",
      "Length: 274, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Lista de columnas a eliminar\n",
    "columns_to_drop = ['Unnamed: 0', 'patient_id', 'sex', 'anatom_site_general', 'image_type', 'tbp_tile_type', \n",
    "                   'tbp_lv_location', 'tbp_lv_location_simple', 'attribution', 'copyright_license', \n",
    "                   'lesion_id', 'iddx_full', 'iddx_1', 'iddx_2', 'iddx_3', 'iddx_4', 'iddx_5', \n",
    "                   'mel_mitotic_index', 'mel_thick_mm', 'tbp_lv_dnn_lesion_confidence', \n",
    "                   'combined_anatomical_site']\n",
    "\n",
    "# Eliminar las columnas del DataFrame\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Sumar los valores de todas las columnas restantes\n",
    "column_sums = df.sum()\n",
    "\n",
    "# Mostrar la suma de cada columna\n",
    "print(\"Suma de los valores en cada columna después de eliminar las especificadas:\")\n",
    "print(column_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo con las predicciones crudas ha sido guardado en /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/data/nuevo_dataset_con_predicciones_2024.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Asegúrate de que 'X' sea el conjunto de características sobre las cuales el modelo predice\n",
    "X = df.drop(columns=['isic_id', 'target'])  # Eliminar columnas no relevantes para la predicción\n",
    "\n",
    "# 3. Hacer predicciones crudas (probabilidades)\n",
    "predicciones_crudas = modelo.predict_proba(X)  # Obtenemos las probabilidades\n",
    "\n",
    "# Si es un problema binario, puedes querer la probabilidad solo de la clase positiva\n",
    "# (asumiendo que la clase positiva es la segunda columna de la matriz de probabilidades)\n",
    "probabilidades_clase_positiva = predicciones_crudas[:, 1]\n",
    "\n",
    "# 4. Crear un nuevo dataframe con 'isic_id', 'target' y las predicciones crudas\n",
    "df_resultados = df[['isic_id', 'target']].copy()  # Copiar columnas 'isic_id' y 'target'\n",
    "df_resultados['prediccion_cruda'] = probabilidades_clase_positiva  # Añadir columna con las probabilidades crudas\n",
    "\n",
    "# 5. Guardar el nuevo dataset con las predicciones crudas\n",
    "output_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/data/nuevo_dataset_con_predicciones_2024.csv'  # Define dónde guardar el nuevo archivo\n",
    "df_resultados.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"El archivo con las predicciones crudas ha sido guardado en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos una nueva prueba de entrenamiento del modelo de imagenes resnet50 añadiendo la nueva columna como caracteristica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib  # Para cargar predicciones crudas\n",
    "\n",
    "# Suprimir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ruta donde se encuentran las imágenes y el archivo con predicciones crudas\n",
    "image_path = '/Users/luiseduardogarciablanco/Desktop/nueva data cancer/2024/Filtered_images'\n",
    "\n",
    "# Cargar los metadatos\n",
    "metadata_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/data/nuevo_dataset_con_predicciones_2024.csv'\n",
    "metadata = pd.read_csv(metadata_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las imágenes están presentes en la carpeta.\n"
     ]
    }
   ],
   "source": [
    "#comprobacion de imagenes en la carpeta\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Obtener la lista de archivos en el directorio de imágenes\n",
    "image_files = set(os.path.splitext(f)[0] for f in os.listdir(image_path) if f.lower().endswith('.jpg'))\n",
    "\n",
    "# Obtener la lista de isic_id del DataFrame\n",
    "isic_ids = set(metadata['isic_id'])\n",
    "\n",
    "# Verificar qué imágenes están faltando\n",
    "missing_images = isic_ids - image_files\n",
    "if missing_images:\n",
    "    print(f\"Faltan las siguientes imágenes:\")\n",
    "    for img_id in missing_images:\n",
    "        print(f\"- {img_id}.jpg\")\n",
    "else:\n",
    "    print(\"Todas las imágenes están presentes en la carpeta.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Listar los dispositivos físicos disponibles, en este caso, GPUs\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Si hay alguna GPU disponible\n",
    "if len(physical_devices) > 0:\n",
    "    # Permitir que TensorFlow crezca dinámicamente la memoria utilizada en la GPU\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "physical_devices\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305524, 3)\n",
      "(76382, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convertir la columna 'target' a string\n",
    "metadata['target'] = metadata['target'].astype(str)\n",
    "\n",
    "# Dividir los datos en entrenamiento y validación\n",
    "train_df, val_df = train_test_split(metadata, test_size=0.2, stratify=metadata['target'], random_state=42)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Generador personalizado para combinar imágenes y predicción cruda\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, image_dir, batch_size, target_size, shuffle=True, mode='train'):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.shuffle = shuffle\n",
    "        self.mode = mode  # Puede ser 'train' o 'val'\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_data = self.dataframe.iloc[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        images = np.array([self._load_image(file_name) for file_name in batch_data['isic_id']])\n",
    "        predicciones_crudas = np.array(batch_data['prediccion_cruda']).reshape(-1, 1)\n",
    "        labels = np.array(batch_data['target']).astype('float32').reshape(-1, 1)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            return [images, predicciones_crudas], labels\n",
    "        else:\n",
    "            return [images, predicciones_crudas]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.dataframe = self.dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def _load_image(self, image_name):\n",
    "        img_path = os.path.join(self.image_dir, image_name + '.jpg')\n",
    "        img = load_img(img_path, target_size=self.target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = preprocess_input(img_array)  # Aplicar normalización específica de ResNet50\n",
    "        return img_array\n",
    "\n",
    "# Crear los generadores de entrenamiento y validación\n",
    "train_gen = CustomDataGenerator(train_df, image_dir=image_path, batch_size=32, target_size=(256, 256), shuffle=True)\n",
    "val_gen = CustomDataGenerator(val_df, image_dir=image_path, batch_size=32, target_size=(256, 256), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 20:05:43.446921: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-09-06 20:05:43.446951: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-09-06 20:05:43.446956: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-09-06 20:05:43.447232: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-06 20:05:43.447257: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_input (InputLayer)    [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " resnet50 (Functional)       (None, 8, 8, 2048)           2358771   ['image_input[0][0]']         \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 131072)               0         ['resnet50[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  1677734   ['flatten[0][0]']             \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " prediccion_cruda_input (In  [(None, 1)]                  0         []                            \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 129)                  0         ['dropout[0][0]',             \n",
      "                                                                     'prediccion_cruda_input[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    130       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40365186 (153.98 MB)\n",
      "Trainable params: 16777474 (64.00 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Cargar el modelo preentrenado ResNet50 (sin la parte superior)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Congelar las capas del modelo base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Entrada de la imagen\n",
    "image_input = layers.Input(shape=(256, 256, 3), name='image_input')\n",
    "x = base_model(image_input)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Entrada de la predicción cruda\n",
    "prediccion_cruda_input = layers.Input(shape=(1,), name='prediccion_cruda_input')\n",
    "\n",
    "# Concatenar ambas entradas\n",
    "combined = layers.Concatenate()([x, prediccion_cruda_input])\n",
    "\n",
    "# Capa de salida\n",
    "output = layers.Dense(1, activation='sigmoid', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(combined)\n",
    "\n",
    "# Definir el modelo\n",
    "model = models.Model(inputs=[image_input, prediccion_cruda_input], outputs=output)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 20:05:53.989851: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9547/9547 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9988 - precision: 0.0128 - recall: 0.0033 - auc: 0.5653"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 20:36:13.410468: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9547/9547 [==============================] - 4545s 475ms/step - loss: 0.0136 - accuracy: 0.9988 - precision: 0.0128 - recall: 0.0033 - auc: 0.5653 - val_loss: 0.0109 - val_accuracy: 0.9990 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5328\n",
      "Epoch 2/5\n",
      "9547/9547 [==============================] - 6384s 669ms/step - loss: 0.0138 - accuracy: 0.9987 - precision: 0.0784 - recall: 0.0263 - auc: 0.5931 - val_loss: 0.0105 - val_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.0132 - val_auc: 0.5386\n",
      "Epoch 3/5\n",
      "9547/9547 [==============================] - 2055s 215ms/step - loss: 0.0132 - accuracy: 0.9987 - precision: 0.0962 - recall: 0.0329 - auc: 0.6116 - val_loss: 0.0109 - val_accuracy: 0.9990 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5454\n",
      "Epoch 4/5\n",
      "9547/9547 [==============================] - 2042s 214ms/step - loss: 0.0130 - accuracy: 0.9987 - precision: 0.1140 - recall: 0.0428 - auc: 0.6111 - val_loss: 0.0106 - val_accuracy: 0.9990 - val_precision: 0.5000 - val_recall: 0.0132 - val_auc: 0.5518\n",
      "Epoch 5/5\n",
      "9547/9547 [==============================] - 2043s 214ms/step - loss: 0.0124 - accuracy: 0.9988 - precision: 0.1373 - recall: 0.0461 - auc: 0.6221 - val_loss: 0.0103 - val_accuracy: 0.9990 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 00:50:24.195485: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9547/9547 [==============================] - ETA: 0s - loss: 4.5245 - accuracy: 0.8516 - precision_1: 0.0030 - recall_1: 0.4507 - auc: 0.7178"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 01:22:33.651647: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9547/9547 [==============================] - 2324s 243ms/step - loss: 4.5245 - accuracy: 0.8516 - precision_1: 0.0030 - recall_1: 0.4507 - auc: 0.7178 - val_loss: 0.3023 - val_accuracy: 0.9022 - val_precision_1: 0.0055 - val_recall_1: 0.5395 - val_auc: 0.8303\n",
      "Epoch 2/10\n",
      "9547/9547 [==============================] - 2319s 243ms/step - loss: 1.6818 - accuracy: 0.7901 - precision_1: 0.0036 - recall_1: 0.7664 - auc: 0.8401 - val_loss: 0.5072 - val_accuracy: 0.9012 - val_precision_1: 0.0056 - val_recall_1: 0.5526 - val_auc: 0.8006\n",
      "Epoch 3/10\n",
      "9547/9547 [==============================] - 2320s 243ms/step - loss: 1.3801 - accuracy: 0.8108 - precision_1: 0.0042 - recall_1: 0.8092 - auc: 0.8638 - val_loss: 0.5833 - val_accuracy: 0.8493 - val_precision_1: 0.0039 - val_recall_1: 0.5921 - val_auc: 0.7810\n",
      "Epoch 4/10\n",
      "9547/9547 [==============================] - 2319s 243ms/step - loss: 1.0838 - accuracy: 0.8497 - precision_1: 0.0056 - recall_1: 0.8421 - auc: 0.8918 - val_loss: 0.4829 - val_accuracy: 0.9006 - val_precision_1: 0.0059 - val_recall_1: 0.5921 - val_auc: 0.7621\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento inicial (solo las capas superiores)\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=5,\n",
    "    validation_data=val_gen\n",
    ")\n",
    "\n",
    "# Descongelar algunas capas del modelo base para fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compilar de nuevo con una tasa de aprendizaje más baja\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Calcular los pesos de clase\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_df['target']), y=train_df['target'])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entrenamiento con Fine-Tuning\n",
    "history_fine = model.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    validation_data=val_gen,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2386/2386 [==============================] - 403s 169ms/step - loss: 0.3023 - accuracy: 0.9022 - precision_1: 0.0055 - recall_1: 0.5395 - auc: 0.8303\n",
      "Loss: 0.3022826611995697, Accuracy: 0.9021898508071899, Precision: 0.0054856836795806885, Recall: 0.5394737124443054, AUC: 0.8303436636924744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 08:07:40.330648: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2386/2386 [==============================] - 381s 159ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.90      0.95     76276\n",
      "     Class 1       0.01      0.54      0.01        76\n",
      "\n",
      "    accuracy                           0.90     76352\n",
      "   macro avg       0.50      0.72      0.48     76352\n",
      "weighted avg       1.00      0.90      0.95     76352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Función para recoger todas las etiquetas verdaderas del generador\n",
    "def get_all_labels(generator):\n",
    "    labels = []\n",
    "    for i in range(len(generator)):\n",
    "        _, batch_labels = generator[i]\n",
    "        labels.extend(batch_labels)\n",
    "    return np.array(labels).flatten()\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy, precision, recall, auc = model.evaluate(val_gen)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, AUC: {auc}\")\n",
    "\n",
    "# Predecir las probabilidades\n",
    "y_pred_probs = model.predict(val_gen)\n",
    "\n",
    "# Ajustar el umbral de decisión\n",
    "threshold = 0.5\n",
    "y_pred_adjusted = (y_pred_probs > threshold).astype(int).flatten()\n",
    "\n",
    "# Obtener las etiquetas verdaderas desde el generador\n",
    "y_true = get_all_labels(val_gen)\n",
    "\n",
    "# Asegurarse de que el número de predicciones coincida con el número de etiquetas verdaderas\n",
    "assert len(y_pred_adjusted) == len(y_true), \"El número de predicciones no coincide con el número de etiquetas reales.\"\n",
    "\n",
    "# Calcular y mostrar el reporte de clasificación\n",
    "print(classification_report(y_true, y_pred_adjusted, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "salida del modelo entrenado con la metadata total de 2024 con el añadido de la columna de la prediccion del primer modelo\n",
    "\n",
    "2386/2386 [==============================] - 381s 159ms/step\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0       1.00      0.90      0.95     76276\n",
    "     Class 1       0.01      0.54      0.01        76\n",
    "\n",
    "    accuracy                           0.90     76352\n",
    "   macro avg       0.50      0.72      0.48     76352\n",
    "weighted avg       1.00      0.90      0.95     76352\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl\n"
     ]
    }
   ],
   "source": [
    "# Ruta donde guardar el modelo\n",
    "model_save_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl'\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save(model_save_path)\n",
    "print(f\"Modelo guardado en {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
