{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo con las predicciones crudas ha sido guardado en /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/data/nuevo_dataset_con_predicciones.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib  # Importar joblib directamente\n",
    "\n",
    "# 1. Cargar el modelo entrenado\n",
    "model_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/metadata_model.pkl'  # Reemplaza con la ruta de tu modelo\n",
    "modelo = joblib.load(model_path)  # Cargar el modelo entrenado\n",
    "\n",
    "# 2. Cargar el dataset de entrada (con los metadatos que usarás para predecir)\n",
    "dataset_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/data/dataset_flask.csv'  # Reemplaza con la ruta del dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Asegúrate de que 'X' sea el conjunto de características sobre las cuales el modelo predice\n",
    "X = df.drop(columns=['isic_id', 'target'])  # Eliminar columnas no relevantes para la predicción\n",
    "\n",
    "# 3. Hacer predicciones crudas (probabilidades)\n",
    "predicciones_crudas = modelo.predict_proba(X)  # Obtenemos las probabilidades\n",
    "\n",
    "# Si es un problema binario, puedes querer la probabilidad solo de la clase positiva\n",
    "# (asumiendo que la clase positiva es la segunda columna de la matriz de probabilidades)\n",
    "probabilidades_clase_positiva = predicciones_crudas[:, 1]\n",
    "\n",
    "# 4. Crear un nuevo dataframe con 'isic_id', 'target' y las predicciones crudas\n",
    "df_resultados = df[['isic_id', 'target']].copy()  # Copiar columnas 'isic_id' y 'target'\n",
    "df_resultados['prediccion_cruda'] = probabilidades_clase_positiva  # Añadir columna con las probabilidades crudas\n",
    "\n",
    "# 5. Guardar el nuevo dataset con las predicciones crudas\n",
    "output_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/data/nuevo_dataset_con_predicciones.csv'  # Define dónde guardar el nuevo archivo\n",
    "df_resultados.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"El archivo con las predicciones crudas ha sido guardado en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos una nueva prueba de entrenamiento del modelo de imagenes resnet50 añadiendo la nueva columna como caracteristica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib  # Para cargar predicciones crudas\n",
    "\n",
    "# Suprimir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ruta donde se encuentran las imágenes y el archivo con predicciones crudas\n",
    "image_path = '/Users/luiseduardogarciablanco/Desktop/nueva data cancer/test web/jpg_ensambled_model'\n",
    "\n",
    "# Cargar los metadatos\n",
    "metadata_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/data/nuevo_dataset_con_predicciones.csv'\n",
    "metadata = pd.read_csv(metadata_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Listar los dispositivos físicos disponibles, en este caso, GPUs\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Si hay alguna GPU disponible\n",
    "if len(physical_devices) > 0:\n",
    "    # Permitir que TensorFlow crezca dinámicamente la memoria utilizada en la GPU\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "physical_devices\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(711, 3)\n",
      "(178, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convertir la columna 'target' a string\n",
    "metadata['target'] = metadata['target'].astype(str)\n",
    "\n",
    "# Dividir los datos en entrenamiento y validación\n",
    "train_df, val_df = train_test_split(metadata, test_size=0.2, stratify=metadata['target'], random_state=42)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Generador personalizado para combinar imágenes y predicción cruda\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, image_dir, batch_size, target_size, shuffle=True, mode='train'):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.shuffle = shuffle\n",
    "        self.mode = mode  # Puede ser 'train' o 'val'\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_data = self.dataframe.iloc[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        images = np.array([self._load_image(file_name) for file_name in batch_data['isic_id']])\n",
    "        predicciones_crudas = np.array(batch_data['prediccion_cruda']).reshape(-1, 1)\n",
    "        labels = np.array(batch_data['target']).astype('float32').reshape(-1, 1)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            return [images, predicciones_crudas], labels\n",
    "        else:\n",
    "            return [images, predicciones_crudas]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.dataframe = self.dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def _load_image(self, image_name):\n",
    "        img_path = os.path.join(self.image_dir, image_name + '.jpg')\n",
    "        img = load_img(img_path, target_size=self.target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = preprocess_input(img_array)  # Aplicar normalización específica de ResNet50\n",
    "        return img_array\n",
    "\n",
    "# Crear los generadores de entrenamiento y validación\n",
    "train_gen = CustomDataGenerator(train_df, image_dir=image_path, batch_size=32, target_size=(256, 256), shuffle=True)\n",
    "val_gen = CustomDataGenerator(val_df, image_dir=image_path, batch_size=32, target_size=(256, 256), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_input (InputLayer)    [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " resnet50 (Functional)       (None, 8, 8, 2048)           2358771   ['image_input[0][0]']         \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 131072)               0         ['resnet50[0][0]']            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128)                  1677734   ['flatten_2[0][0]']           \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128)                  0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " prediccion_cruda_input (In  [(None, 1)]                  0         []                            \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 129)                  0         ['dropout_2[0][0]',           \n",
      " )                                                                   'prediccion_cruda_input[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    130       ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40365186 (153.98 MB)\n",
      "Trainable params: 16777474 (64.00 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Cargar el modelo preentrenado ResNet50 (sin la parte superior)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Congelar las capas del modelo base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Entrada de la imagen\n",
    "image_input = layers.Input(shape=(256, 256, 3), name='image_input')\n",
    "x = base_model(image_input)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Entrada de la predicción cruda\n",
    "prediccion_cruda_input = layers.Input(shape=(1,), name='prediccion_cruda_input')\n",
    "\n",
    "# Concatenar ambas entradas\n",
    "combined = layers.Concatenate()([x, prediccion_cruda_input])\n",
    "\n",
    "# Capa de salida\n",
    "output = layers.Dense(1, activation='sigmoid', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(combined)\n",
    "\n",
    "# Definir el modelo\n",
    "model = models.Model(inputs=[image_input, prediccion_cruda_input], outputs=output)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:19:25.108762: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - ETA: 0s - loss: 0.9405 - accuracy: 0.6222 - precision_3: 0.5714 - recall_3: 0.5677 - auc: 0.6572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:19:30.795350: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 9s 296ms/step - loss: 0.9405 - accuracy: 0.6222 - precision_3: 0.5714 - recall_3: 0.5677 - auc: 0.6572 - val_loss: 0.5140 - val_accuracy: 0.7500 - val_precision_3: 0.6742 - val_recall_3: 0.8451 - val_auc: 0.8588\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 239ms/step - loss: 0.7209 - accuracy: 0.7088 - precision_3: 0.6770 - recall_3: 0.6396 - auc: 0.7692 - val_loss: 0.4828 - val_accuracy: 0.8000 - val_precision_3: 0.7241 - val_recall_3: 0.8873 - val_auc: 0.8891\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 239ms/step - loss: 0.5075 - accuracy: 0.7628 - precision_3: 0.7296 - recall_3: 0.7273 - auc: 0.8520 - val_loss: 0.4250 - val_accuracy: 0.8188 - val_precision_3: 0.7625 - val_recall_3: 0.8592 - val_auc: 0.8977\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 240ms/step - loss: 0.5361 - accuracy: 0.7727 - precision_3: 0.7500 - recall_3: 0.7258 - auc: 0.8459 - val_loss: 0.3907 - val_accuracy: 0.8000 - val_precision_3: 0.8000 - val_recall_3: 0.7324 - val_auc: 0.9068\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 239ms/step - loss: 0.4890 - accuracy: 0.8040 - precision_3: 0.8021 - recall_3: 0.7346 - auc: 0.8660 - val_loss: 0.3820 - val_accuracy: 0.8125 - val_precision_3: 0.8060 - val_recall_3: 0.7606 - val_auc: 0.9097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:19:55.188597: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - ETA: 0s - loss: 0.7388 - accuracy: 0.7358 - precision_4: 0.7003 - recall_4: 0.6958 - auc: 0.8059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:20:01.940491: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 10s 343ms/step - loss: 0.7388 - accuracy: 0.7358 - precision_4: 0.7003 - recall_4: 0.6958 - auc: 0.8059 - val_loss: 0.4068 - val_accuracy: 0.8375 - val_precision_4: 0.8358 - val_recall_4: 0.7887 - val_auc: 0.9085\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 6s 274ms/step - loss: 0.5074 - accuracy: 0.8082 - precision_4: 0.7599 - recall_4: 0.8170 - auc: 0.8799 - val_loss: 0.4083 - val_accuracy: 0.8250 - val_precision_4: 0.7867 - val_recall_4: 0.8310 - val_auc: 0.9069\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 6s 271ms/step - loss: 0.3532 - accuracy: 0.8622 - precision_4: 0.8397 - recall_4: 0.8479 - auc: 0.9265 - val_loss: 0.4253 - val_accuracy: 0.8500 - val_precision_4: 0.8133 - val_recall_4: 0.8592 - val_auc: 0.9088\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 6s 278ms/step - loss: 0.3339 - accuracy: 0.8665 - precision_4: 0.8267 - recall_4: 0.8803 - auc: 0.9370 - val_loss: 0.4916 - val_accuracy: 0.8250 - val_precision_4: 0.7792 - val_recall_4: 0.8451 - val_auc: 0.8977\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento inicial (solo las capas superiores)\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=5,\n",
    "    validation_data=val_gen\n",
    ")\n",
    "\n",
    "# Descongelar algunas capas del modelo base para fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compilar de nuevo con una tasa de aprendizaje más baja\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Calcular los pesos de clase\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_df['target']), y=train_df['target'])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entrenamiento con Fine-Tuning\n",
    "history_fine = model.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    validation_data=val_gen,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 189ms/step - loss: 0.4068 - accuracy: 0.8375 - precision_4: 0.8358 - recall_4: 0.7887 - auc: 0.9085\n",
      "Loss: 0.4068334102630615, Accuracy: 0.8374999761581421, Precision: 0.8358209133148193, Recall: 0.7887324094772339, AUC: 0.9084506630897522\n",
      "5/5 [==============================] - 1s 176ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.84      0.88      0.86        89\n",
      "     Class 1       0.84      0.79      0.81        71\n",
      "\n",
      "    accuracy                           0.84       160\n",
      "   macro avg       0.84      0.83      0.83       160\n",
      "weighted avg       0.84      0.84      0.84       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Función para recoger todas las etiquetas verdaderas del generador\n",
    "def get_all_labels(generator):\n",
    "    labels = []\n",
    "    for i in range(len(generator)):\n",
    "        _, batch_labels = generator[i]\n",
    "        labels.extend(batch_labels)\n",
    "    return np.array(labels).flatten()\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy, precision, recall, auc = model.evaluate(val_gen)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, AUC: {auc}\")\n",
    "\n",
    "# Predecir las probabilidades\n",
    "y_pred_probs = model.predict(val_gen)\n",
    "\n",
    "# Ajustar el umbral de decisión\n",
    "threshold = 0.5\n",
    "y_pred_adjusted = (y_pred_probs > threshold).astype(int).flatten()\n",
    "\n",
    "# Obtener las etiquetas verdaderas desde el generador\n",
    "y_true = get_all_labels(val_gen)\n",
    "\n",
    "# Asegurarse de que el número de predicciones coincida con el número de etiquetas verdaderas\n",
    "assert len(y_pred_adjusted) == len(y_true), \"El número de predicciones no coincide con el número de etiquetas reales.\"\n",
    "\n",
    "# Calcular y mostrar el reporte de clasificación\n",
    "print(classification_report(y_true, y_pred_adjusted, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "salida del entrenamiento del modelo de imagenes con el añadido de la columna de resultado del modleo entrenado solo con mtadatos\n",
    "\n",
    "5/5 [==============================] - 1s 189ms/step - loss: 0.4068 - accuracy: 0.8375 - precision_4: 0.8358 - recall_4: 0.7887 - auc: 0.9085\n",
    "Loss: 0.4068334102630615, Accuracy: 0.8374999761581421, Precision: 0.8358209133148193, Recall: 0.7887324094772339, AUC: 0.9084506630897522\n",
    "5/5 [==============================] - 1s 176ms/step\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0       0.84      0.88      0.86        89\n",
    "     Class 1       0.84      0.79      0.81        71\n",
    "\n",
    "    accuracy                           0.84       160\n",
    "   macro avg       0.84      0.83      0.83       160\n",
    "weighted avg       0.84      0.84      0.84       160\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl\n"
     ]
    }
   ],
   "source": [
    "# Ruta donde guardar el modelo\n",
    "model_save_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl'\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save(model_save_path)\n",
    "print(f\"Modelo guardado en {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
